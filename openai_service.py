import os
import json
import logging
from openai import OpenAI
from typing import Dict, List, Any, Optional

# OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–
# the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
# do not change this unless explicitly requested by the user
import httpx
import time

# åˆ›å»ºå¸¦ä¼˜åŒ–è¿æ¥é…ç½®çš„å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    timeout=httpx.Timeout(40.0, connect=15.0),  # ä¼˜åŒ–è¶…æ—¶ï¼šè¿æ¥15ç§’ï¼Œè¯»å–40ç§’
    http_client=httpx.Client(
        limits=httpx.Limits(max_connections=10, max_keepalive_connections=5),
        timeout=httpx.Timeout(40.0, connect=15.0)
    )
)

logger = logging.getLogger(__name__)


class AngelaAI:
    """Angela - éåŠ³åŠ¡æ”¶å…¥ç®¡é“è®¾è®¡AIæœåŠ¡"""

    def __init__(self):
        self.default_model = "gpt-4o"  # é»˜è®¤æ¨¡å‹
        self.default_max_tokens = 2500  # é»˜è®¤tokenæ•°é‡

    def get_model_config(self, config_type='main_analysis'):
        """ä»æ•°æ®åº“è·å–æ¨¡å‹é…ç½®"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
            import importlib
            models_module = importlib.import_module('models')
            ModelConfig = getattr(models_module, 'ModelConfig')
            config = ModelConfig.get_config(config_type, self.default_model)
            return config
        except Exception as e:
            logger.warning(f"Failed to get model config: {e}, using defaults")
            return {
                'model': self.default_model,
                'temperature': 0.7,
                'max_tokens': self.default_max_tokens,
                'timeout': 45
            }

    def _call_openai_with_retry(self, **kwargs):
        """è°ƒç”¨OpenAI APIï¼Œå¸¦å¼ºåŒ–é‡è¯•æœºåˆ¶"""
        logger.info("=== _call_openai_with_retryæ–¹æ³•è¢«è°ƒç”¨ ===")
        logger.info(f"ä¼ å…¥å‚æ•°: model={kwargs.get('model')}, timeout={kwargs.get('timeout')}")
        max_retries = 2  # å‡å°‘é‡è¯•æ¬¡æ•°ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
        for attempt in range(max_retries):
            try:
                logger.info(f"æ­£åœ¨è°ƒç”¨OpenAI API (å°è¯• {attempt + 1}/{max_retries})...")
                
                # ä¸ºæ¯æ¬¡é‡è¯•åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯è¿æ¥ï¼Œé¿å…è¿æ¥å¤ç”¨é—®é¢˜
                if attempt > 0:
                    fresh_client = OpenAI(
                        api_key=os.environ.get("OPENAI_API_KEY"),
                        timeout=httpx.Timeout(45.0, connect=15.0)  # ç¼©çŸ­è¶…æ—¶æ—¶é—´
                    )
                    return fresh_client.chat.completions.create(**kwargs)
                else:
                    return client.chat.completions.create(**kwargs)
                    
            except (httpx.TimeoutException, httpx.ConnectError, ConnectionError, 
                    httpx.ReadTimeout, httpx.ConnectTimeout, TimeoutError,
                    OSError, ConnectionResetError, BrokenPipeError) as e:
                if attempt < max_retries - 1:
                    wait_time = 2 * (attempt + 1)  # ç¼©çŸ­ç­‰å¾…æ—¶é—´: 2s, 4s
                    logger.warning(f"OpenAI APIç½‘ç»œè¶…æ—¶ (å°è¯• {attempt + 1}): {str(e)}, {wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"OpenAI APIç½‘ç»œè¶…æ—¶ï¼Œæœ€ç»ˆå¤±è´¥: {str(e)}")
                    # å¯¹äºç½‘ç»œé—®é¢˜ï¼ŒæŠ›å‡ºè¿æ¥é”™è¯¯è€Œä¸æ˜¯è¿”å›None
                    if "read timed out" in str(e).lower() or "timeout" in str(e).lower():
                        time.sleep(2)
                        continue
                    else:
                        raise ConnectionError("ç½‘ç»œè¿æ¥ä¸ç¨³å®š")
            except Exception as e:
                import traceback
                logger.error(f"ğŸ’¥ OpenAI APIè°ƒç”¨é‡åˆ°å…¶ä»–é”™è¯¯: {str(e)}")
                logger.error(f"ğŸ’¥ é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"ğŸ’¥ å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
                logger.error(f"ğŸ’¥ ä¼ å…¥çš„å‚æ•°: {kwargs}")
                raise e

    def format_role_to_chinese(self, role_identifier: str) -> str:
        """å°†è‹±æ–‡è§’è‰²æ ‡è¯†ç¬¦è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤º"""
        role_mapping = {
            # éœ€æ±‚æ–¹è§’è‰²
            'enterprise_owner': 'ä¼ä¸šä¸»',
            'store_owner': 'å®ä½“åº—ä¸»', 
            'department_head': 'éƒ¨é—¨è´Ÿè´£äºº',
            'brand_manager': 'ä¸»ç†äºº',
            # äº¤ä»˜æ–¹è§’è‰²
            'product_provider': 'äº§å“æ–¹',
            'service_provider': 'æœåŠ¡æ–¹',
            'traffic_provider': 'æµé‡æ–¹',
            'other_provider': 'å…¶ä»–èµ„æºæ–¹'
        }
        return role_mapping.get(role_identifier, role_identifier)

    def get_role_type_by_identifier(self, role_identifier: str) -> str:
        """æ ¹æ®è§’è‰²æ ‡è¯†ç¬¦è·å–è§’è‰²ç±»å‹ï¼ˆéœ€æ±‚æ–¹/äº¤ä»˜æ–¹ç­‰ï¼‰"""
        demand_roles = ['enterprise_owner', 'store_owner', 'department_head', 'brand_manager']
        delivery_roles = ['product_provider', 'service_provider', 'traffic_provider', 'other_provider']
        
        if role_identifier in demand_roles:
            return 'éœ€æ±‚æ–¹'
        elif role_identifier in delivery_roles:
            return 'äº¤ä»˜æ–¹'
        else:
            return 'å…¶ä»–æ–¹'

    def format_make_happy(self, make_happy_data) -> str:
        """æ ¼å¼åŒ–åŠ¨æœºæ ‡ç­¾æ•°æ®"""
        if not make_happy_data:
            return "æœªæŒ‡å®š"

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆåˆ†å‰²æˆåˆ—è¡¨
        if isinstance(make_happy_data, str):
            make_happy_list = make_happy_data.split(',')
        else:
            make_happy_list = make_happy_data

        # æ˜ å°„å€¼åˆ°æ˜¾ç¤ºæ–‡æœ¬ï¼ˆåŒ…å«æ–°çš„å®é™…æ ‡ç­¾ï¼‰
        label_map = {
            'recognition': 'è·å¾—è®¤å¯/åå£°',
            'learning': 'å­¦ä¹ æ–°çŸ¥è¯†/æŠ€èƒ½',
            'networking': 'æ‰©å±•äººè„‰/ç¤¾äº¤åœˆ',
            'fun': 'å¨±ä¹æ”¾æ¾/äº«å—è¿‡ç¨‹',
            'helping': 'å¸®åŠ©ä»–äºº/ç¤¾ä¼šä»·å€¼',
            'money': 'è·å¾—é‡‘é’±/ç»æµæ”¶ç›Š',
            'power': 'è·å¾—æƒåŠ›/å½±å“åŠ›',
            'creation': 'åˆ›é€ ä½œå“/è¡¨è¾¾è‡ªæˆ‘',
            'growth': 'ä¸ªäººæˆé•¿/çªç ´æŒ‘æˆ˜',
            # æ–°å¢å®é™…ä½¿ç”¨çš„æ ‡ç­¾
            'bring_leads': 'å¸¦æ¥å®¢æˆ·/å¼•æµ',
            'recurring_income': 'è·å¾—æŒç»­æ”¶å…¥',
            'no_conflict_current_partner': 'ä¸å†²çªç°æœ‰åˆä½œ',
            'brand_exposure': 'å“ç‰Œæ›å…‰',
            'expand_network': 'æ‹“å±•ç½‘ç»œ/äººè„‰'
        }

        return "ã€".join([
            label_map.get(item.strip(), item.strip())
            for item in make_happy_list
        ])

    def format_external_resources(self, resources_data: List[str]) -> str:
        """æ ¼å¼åŒ–å¤–éƒ¨èµ„æºæ•°æ®"""
        if not resources_data:
            return "æ— å¯ç”¨å¤–éƒ¨èµ„æº"

        # æŒ‰èµ„æºç±»å‹åˆ†ç»„
        categories = {'èµ„é‡‘æ”¯æŒ': [], 'å¸‚åœºæ¸ é“': [], 'æ‰§è¡Œèƒ½åŠ›': [], 'æˆ˜ç•¥åˆä½œ': []}

        # æ ¹æ®èµ„æºå†…å®¹åˆ†ç±»ï¼ˆç®€åŒ–ç‰ˆï¼‰
        for resource in resources_data:
            if any(keyword in resource
                   for keyword in ['èµ„é‡‘', 'æŠ•èµ„', 'é¢„ç®—', 'èµåŠ©']):
                categories['èµ„é‡‘æ”¯æŒ'].append(resource)
            elif any(keyword in resource
                     for keyword in ['æ¸ é“', 'å¹³å°', 'åª’ä½“', 'ç¤¾ç¾¤']):
                categories['å¸‚åœºæ¸ é“'].append(resource)
            elif any(keyword in resource
                     for keyword in ['æŠ€æœ¯', 'å›¢é˜Ÿ', 'è®¾å¤‡', 'å·¥å…·']):
                categories['æ‰§è¡Œèƒ½åŠ›'].append(resource)
            else:
                categories['æˆ˜ç•¥åˆä½œ'].append(resource)

        result = []
        for category, items in categories.items():
            if items:
                result.append(f"{category}: {', '.join(items)}")

        return "; ".join(result) if result else "é€šç”¨å¤–éƒ¨èµ„æºå¯ç”¨"

    def get_knowledge_base_snippets(self, project_description: str,
                                    key_persons: List[Dict],
                                    external_resources: List[str],
                                    db_session) -> str:
        """ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ç‰‡æ®µ"""
        try:
            import importlib
            models_module = importlib.import_module('models')
            KnowledgeItem = getattr(models_module, 'KnowledgeItem')

            # è·å–æ´»è·ƒçŠ¶æ€çš„çŸ¥è¯†åº“æ¡ç›®
            knowledge_items = db_session.query(KnowledgeItem).filter(
                KnowledgeItem.status == 'active').all()

            if not knowledge_items:
                return self.get_core_knowledge_fallback()

            # ä¼˜å…ˆæŸ¥æ‰¾éåŠ³åŠ¡æ”¶å…¥ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹
            non_labor_income_items = [
                item for item in knowledge_items if item.content_summary and
                ('éåŠ³åŠ¡æ”¶å…¥' in item.content_summary or 'ç®¡é“' in
                 item.content_summary or 'ç§Ÿé‡‘' in item.content_summary or 'è‚¡ä»½'
                 in item.content_summary or 'ç‰ˆæƒ' in item.content_summary
                 or 'Bonnie' in item.content_summary or 'Angela' in
                 item.content_summary or 'æ¥šæ¥š' in item.content_summary or 'çŸ¥äº†çŒ´'
                 in item.content_summary or 'è‹±è¯­åŸ¹è®­' in item.content_summary
                 or 'å•†é“º' in item.content_summary)
            ]

            relevant_snippets = []

            # å¦‚æœæ‰¾åˆ°éåŠ³åŠ¡æ”¶å…¥ç›¸å…³å†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨
            if non_labor_income_items:
                for item in non_labor_income_items[:2]:  # æœ€å¤š2ä¸ªæ ¸å¿ƒæ¡ç›®
                    if item.content_summary:
                        # æå–æ›´å¤šæœ‰ç”¨ä¿¡æ¯ï¼Œç‰¹åˆ«å…³æ³¨æ ¸å¿ƒåŸç†å’Œæ¡ˆä¾‹
                        summary = item.content_summary[:800]  # å¢åŠ åˆ°800å­—ç¬¦è·å–æ›´å¤šä¿¡æ¯
                        relevant_snippets.append(f"â€¢ {summary}")
                        item.usage_count += 1

            # è¡¥å……å…¶ä»–ç›¸å…³æ¡ç›®
            other_items = [
                item for item in knowledge_items
                if item not in non_labor_income_items
            ]
            for item in other_items[:2]:  # æœ€å¤šå†è¡¥å……2ä¸ª
                if item.content_summary and len(relevant_snippets) < 4:
                    summary = item.content_summary[:300]
                    relevant_snippets.append(f"â€¢ {summary}")
                    item.usage_count += 1

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œè¿”å›æ ¸å¿ƒçŸ¥è¯†è¦ç‚¹
            if not relevant_snippets:
                return self.get_core_knowledge_fallback()

            return "\n".join(relevant_snippets)

        except Exception as e:
            logger.error(f"Knowledge base retrieval error: {e}")
            return self.get_core_knowledge_fallback()

    def get_core_knowledge_fallback(self) -> str:
        """å½“çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥æ—¶çš„æ ¸å¿ƒçŸ¥è¯†è¦ç‚¹"""
        return """â€¢ éåŠ³åŠ¡æ”¶å…¥æ ¸å¿ƒå…¬å¼ï¼šæ„è¯†+èƒ½é‡+èƒ½åŠ›ï¼ˆè¡ŒåŠ¨ï¼‰=ç»“æœ
â€¢ ä¸ƒå¤§ç±»å‹ï¼šç§Ÿé‡‘ï¼ˆä¸‡ç‰©çš†å¯ç§Ÿï¼‰ã€åˆ©æ¯ã€è‚¡ä»½/çº¢åˆ©ã€ç‰ˆæƒã€ä¸“åˆ©ã€ä¼ä¸šè¿é”ã€å›¢é˜Ÿæ”¶ç›Š
â€¢ ä¸‰æ­¥æ³•åˆ™ï¼šç›˜èµ„æºâ†’æ­ç®¡é“â†’åŠ¨çœŸæ ¼
â€¢ æ ¸å¿ƒåŸåˆ™ï¼šè®©å…³é”®ç¯èŠ‚çš„å…³é”®äººç‰©éƒ½é«˜å…´ï¼Œä¸¥æ ¼åŒºåˆ†éœ€æ¢å–çš„äººç‰©èµ„æºvså¯ç›´æ¥åŠ¨ç”¨çš„å¤–éƒ¨èµ„æº
â€¢ æˆåŠŸè¦ç´ ï¼š1)è®¾è®¡å…±èµ¢æœºåˆ¶ 2)æŒæ¡æ ¸å¿ƒä¿¡æ¯+ç­›é€‰è§„åˆ™ 3)å‰ç½®åˆä½œè§„åˆ™
â€¢ æˆåŠŸæ¡ˆä¾‹å‚è€ƒï¼šBonnieè‹±è¯­åŸ¹è®­ç®¡é“ï¼ˆè¿æ¥è§„åˆ’å¸ˆ+æœºæ„ï¼Œå¹´40ä¸‡æ”¶å…¥ï¼‰ã€Angelaå•†é“ºäºŒæˆ¿ä¸œï¼ˆ1ä¸‡å¯åŠ¨ï¼Œ8å¹´72ä¸‡æ”¶å…¥ï¼‰ã€æ¥šæ¥šçŸ¥äº†çŒ´ç®¡é“ï¼ˆ7æ¡ç®¡é“ï¼Œå¹´70ä¸‡æ”¶å…¥ï¼‰"""

    def generate_income_paths(self, form_data: Dict[str, Any],
                              db_session) -> Dict[str, Any]:
        """ç”ŸæˆéåŠ³åŠ¡æ”¶å…¥è·¯å¾„"""
        logger.info("=== Angela AI generate_income_pathsæ–¹æ³•å¼€å§‹ ===")
        logger.info(f"è¾“å…¥æ•°æ®: {json.dumps(form_data, ensure_ascii=False)}")
        try:
            # æå–è¡¨å•æ•°æ®
            project_name = form_data.get('projectName', 'æœªå‘½åé¡¹ç›®')
            project_description = form_data.get('projectDescription', '')
            key_persons = form_data.get('keyPersons', [])
            external_resources = form_data.get('externalResources', [])

            # è·å–çŸ¥è¯†åº“ç‰‡æ®µ - ç®€åŒ–ä»¥å‡å°‘prompté•¿åº¦
            try:
                kb_snippets = self.get_knowledge_base_snippets(
                    project_description, key_persons, external_resources,
                    db_session)
                # é™åˆ¶çŸ¥è¯†åº“å†…å®¹é•¿åº¦
                if len(kb_snippets) > 500:
                    kb_snippets = kb_snippets[:500] + "..."
            except Exception as kb_error:
                logger.warning(f"Knowledge base retrieval failed: {kb_error}")
                kb_snippets = self.get_core_knowledge_fallback()

            # ç®€åŒ–ç³»ç»Ÿæç¤º - ä¸“æ³¨äºä¸ªæ€§åŒ–åˆ†æ  
            system_prompt = """ä½ æ˜¯Angelaï¼Œä¸“ä¸šçš„éåŠ³åŠ¡æ”¶å…¥ç®¡é“è®¾è®¡å¸ˆã€‚

## ä»»åŠ¡
æ ¹æ®ç”¨æˆ·çš„å…·ä½“é¡¹ç›®ç‰¹ç‚¹ï¼Œè®¾è®¡ä¸ªæ€§åŒ–çš„éåŠ³åŠ¡æ”¶å…¥ç®¡é“æ–¹æ¡ˆã€‚

## æ ¸å¿ƒåŸåˆ™
- éåŠ³åŠ¡æ”¶å…¥ç±»å‹ï¼šç§Ÿé‡‘ã€åˆ©æ¯ã€è‚¡ä»½ã€ç‰ˆæƒã€å±…é—´ã€ä¼ä¸šè¿é”ã€å›¢é˜Ÿæ”¶ç›Š
- è®¾è®¡è€…é€šè¿‡æ•´åˆèµ„æºè·å¾—æ”¶ç›Šï¼Œè€Œéä¾èµ–æŒç»­åŠ³åŠ¨
- è®©æ‰€æœ‰å‚ä¸æ–¹è·ç›Šï¼Œè®¾è®¡è€…æ§åˆ¶å…³é”®ç¯èŠ‚

## è¦æ±‚
- æ·±å…¥åˆ†æé¡¹ç›®ç‰¹ç‚¹ï¼Œæä¾›é’ˆå¯¹æ€§å»ºè®®
- é¿å…é€šç”¨æ¨¡æ¿ï¼Œä½“ç°é¡¹ç›®ç‹¬ç‰¹æ€§  
- è¯´æ˜å…·ä½“çš„æ”¶ç›Šæœºåˆ¶å’Œç¬¬ä¸€æ­¥è¡ŒåŠ¨

## åˆ†æè¦ç‚¹
é’ˆå¯¹è¿™ä¸ªå…·ä½“é¡¹ç›®ï¼Œè¯·åˆ†æï¼š
1. é¡¹ç›®çš„ç‹¬ç‰¹æœºä¼šç‚¹åœ¨å“ªé‡Œï¼Ÿ
2. ç°æœ‰èµ„æºå¦‚ä½•å½¢æˆæ”¶ç›Šé—­ç¯ï¼Ÿ  
3. è®¾è®¡è€…å¯ä»¥é€šè¿‡ä»€ä¹ˆæ–¹å¼è·å¾—éåŠ³åŠ¡æ”¶å…¥ï¼Ÿ
4. ç¬¬ä¸€æ­¥åº”è¯¥å¦‚ä½•è¡ŒåŠ¨ï¼Ÿ"""

            # æ„é€ ç”¨æˆ·æç¤º
            user_content = f"""ã€é¡¹ç›®åç§°ã€‘{project_name}
ã€é¡¹ç›®èƒŒæ™¯ã€‘{project_description}

ã€å…³é”®äººç‰©ã€‘ï¼ˆå«è§’è‰²ã€èµ„æºã€åŠ¨æœºï¼‰"""

            for i, person in enumerate(key_persons):
                name = person.get('name', f'äººç‰©{i+1}')
                role = person.get('role', '')  # ä¿®æ­£ï¼šä½¿ç”¨roleè€Œä¸æ˜¯roles
                resources = person.get('resources', [])
                make_happy = person.get('make_happy',
                                        '')  # ä¿®æ­£ï¼šä½¿ç”¨make_happyè€Œä¸æ˜¯makeHappy
                notes = person.get('notes', '')

                # å°†è‹±æ–‡è§’è‰²æ ‡è¯†ç¬¦è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤ºåç§°
                role_chinese = self.format_role_to_chinese(role) if role else "æœªæŒ‡å®š"
                role_type = self.get_role_type_by_identifier(role) if role else "å…¶ä»–æ–¹"

                user_content += f"""
- äººç‰©ï¼š{name}ï½œè§’è‰²ï¼š{role_chinese}ï¼ˆ{role_type}ï¼‰
  èµ„æºï¼š{", ".join(resources) if resources else "æ— "}
  åŠ¨æœºæ ‡ç­¾ï¼ˆå¦‚ä½•è®©TAé«˜å…´ï¼‰ï¼š{self.format_make_happy(make_happy)}
  å¤‡æ³¨ï¼š{notes if notes else "æ— "}"""

            user_content += f"""

ã€å¤–éƒ¨èµ„æºï¼ˆå¯ç›´æ¥ä½¿ç”¨çš„èµ„æºæ± ï¼‰ã€‘
{self.format_external_resources(external_resources)}

ã€çŸ¥è¯†åº“è¦ç‚¹ã€‘ï¼ˆåªç»™è¦ç‚¹ï¼Œé¿å…å†—é•¿ï¼‰
{kb_snippets}"""

            # æ„å»ºå…³é”®äººç‰©åˆ—è¡¨ç”¨äºæç¤º
            key_persons_names = ', '.join([
                person.get('name', f'äººç‰©{i+1}')
                for i, person in enumerate(key_persons)
            ])

            # ç®€åŒ–assistant prompt - ä¸“æ³¨äºä¸ªæ€§åŒ–ç”Ÿæˆ
            assistant_prompt = f"""è¯·æ ¹æ®è¿™ä¸ªå…·ä½“é¡¹ç›®ï¼Œç”Ÿæˆä¸ªæ€§åŒ–çš„éåŠ³åŠ¡æ”¶å…¥ç®¡é“å»ºè®®ã€‚

è¦æ±‚ï¼š
1. å¿…é¡»ä½“ç°é¡¹ç›®çš„ç‹¬ç‰¹ç‰¹ç‚¹
2. ç®¡é“åç§°è¦åæ˜ é¡¹ç›®ç‰¹è‰²ï¼Œé¿å…é€šç”¨æ¨¡æ¿
3. é’ˆå¯¹é¡¹ç›®çš„å…·ä½“ç—›ç‚¹å’Œæœºä¼š
4. è¯´æ˜å¦‚ä½•åˆ©ç”¨ç°æœ‰èµ„æº

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
  "overview": {{
    "situation": "é¡¹ç›®åˆ†æï¼ˆé’ˆå¯¹å…·ä½“é¡¹ç›®æƒ…å†µï¼‰",
    "income_type": "é€‚ç”¨çš„éåŠ³åŠ¡æ”¶å…¥ç±»å‹",
    "core_insight": "æ ¸å¿ƒæ´å¯Ÿï¼ˆé¡¹ç›®çš„ç‹¬ç‰¹æœºä¼šï¼‰",
    "gaps": ["ç¼ºå°‘çš„å…³é”®è§’è‰²"],
    "suggested_roles_to_hunt": []
  }},
  "pipelines": [
    {{
      "id": "pipeline_1", 
      "name": "é’ˆå¯¹é¡¹ç›®çš„å…·ä½“ç®¡é“åç§°",
      "income_mechanism": {{
        "type": "æ‰€å±çš„éåŠ³åŠ¡æ”¶å…¥ç±»å‹ï¼ˆä¸ƒå¤§ç±»ä¹‹ä¸€æˆ–ç»„åˆï¼‰",
        "trigger": "æ”¶ç›Šè§¦å‘ç‚¹ï¼ˆé’±ä»å“ªæ¥ï¼‰",
        "settlement": "ç»“ç®—æ–¹å¼ï¼ˆæŒ‰å•/æŒ‰æœŸ/åˆ†çº¢/æˆæƒè´¹ç­‰ï¼‰"
      }},
      "parties_structure": [
        {{
          "party": "è®¾è®¡è€…ï¼ˆä½ ï¼‰",
          "role_type": "ç»Ÿç­¹æ–¹",
          "resources": ["ä½ æä¾›çš„èµ„æºæˆ–è§„åˆ™ï¼ˆä¾‹å¦‚ï¼šå¯¹æ¥æƒã€æ’æœŸæƒã€ç»“ç®—å£å¾„ã€å…±ç®¡å…¥å£ï¼‰"],
          "role_value": "ä½ åœ¨é—­ç¯ä¸­çš„ä»·å€¼ï¼ˆç»Ÿç­¹/æ’®åˆ/è§„åˆ™åˆ¶å®š/å…±ç®¡ç»“ç®—ç­‰ï¼‰",
          "make_them_happy": "å¦‚ä½•ç¡®ä¿è‡ªå·±ä¸è¢«è·³è¿‡å¹¶æŒç»­è·åˆ©ï¼ˆä½ç½®/è§„åˆ™/ç»“ç®—æœºåˆ¶ï¼‰"
        }}
        // å…¶åå¿…é¡»é€ä¸€åŠ å…¥ User Content ä¸­çš„æ‰€æœ‰å…³é”®äººç‰©ï¼Œç»“æ„æ¨¡æ¿å¦‚ä¸‹ï¼š
        // {{
        //   "party": "<å¿…é¡»ä¸ç”¨æˆ·è¾“å…¥çš„äººå/ç§°è°“å®Œå…¨ä¸€è‡´>",
        //   "role_type": "éœ€æ±‚æ–¹/äº¤ä»˜æ–¹/èµ„é‡‘æ–¹/ç»Ÿç­¹æ–¹ï¼ˆé€šå¸¸éç»Ÿç­¹æ–¹ï¼‰",
        //   "resources": ["è¯¥äººç‰©å¯æä¾›çš„èµ„æºï¼ˆå°½é‡å…·ä½“ã€æ¡†æ¶å±‚é¢ï¼‰"],
        //   "role_value": "è¯¥äººç‰©åœ¨é—­ç¯ä¸­çš„ä½ç½®/ä½œç”¨ï¼ˆæ¡†æ¶å±‚é¢ï¼‰",
        //   "make_them_happy": "å¦‚ä½•è®©TAé«˜å…´ï¼ˆå¯¹åº”çš„åŠ¨æœº/æ¿€åŠ±ï¼Œæ¡†æ¶å±‚é¢ï¼‰"
        // }}
        // è‹¥å…³é”®äººç‰©ä¸è¶³æˆ–ç¼ºå°‘æŸç±»è§’è‰²ï¼Œå¿…é¡»åŠ å…¥"å¾…è¡¥é½è§’è‰²"ï¼š
        // {{
        //   "party": "ã€å¾…è¡¥é½ã€‘è§’è‰²åç§°",
        //   "role_type": "éœ€æ±‚æ–¹/äº¤ä»˜æ–¹/èµ„é‡‘æ–¹",
        //   "resources": ["è¯¥è§’è‰²åº”æä¾›çš„èµ„æº"],
        //   "role_value": "è¯¥è§’è‰²åœ¨é—­ç¯ä¸­çš„é‡è¦ä½œç”¨",
        //   "make_them_happy": "å¦‚ä½•å¸å¼•å’Œæ¿€åŠ±è¯¥è§’è‰²åŠ å…¥"
        // }}
      ],
      "framework_logic": {{
        "resource_chain": "èµ„æºå¦‚ä½•ä¸²è”å½¢æˆé—­ç¯ï¼ˆæ¡†æ¶æè¿°ï¼Œä¸å†™å¹³å°ä¸é¢‘æ¬¡ï¼‰",
        "motivation_match": "å„æ–¹åŠ¨æœºå¦‚ä½•è¢«æ»¡è¶³ï¼ˆæ¡†æ¶æè¿°ï¼‰",
        "designer_position": "è®¾è®¡è€…åœ¨æ¡†æ¶ä¸­çš„ç»Ÿç­¹/é˜²ç»•è¡Œæœºåˆ¶ï¼ˆå¦‚å…±ç®¡å…¥å£ã€åˆåŒ/ç»“ç®—å£å¾„ï¼‰",
        "designer_income": "è®¾è®¡è€…é€šè¿‡å“ªä¸€ç±»éåŠ³åŠ¡æ–¹å¼è·å¾—æ”¶ç›Šï¼ˆé¡»å±äºä¸ƒå¤§ç±»ä¹‹ä¸€æˆ–ç»„åˆï¼‰"
      }},
      "mvp": "æœ€å°é—­ç¯ï¼šç”¨1-3å¥è¯è¯´æ˜æ–¹æ¡ˆå¦‚ä½•è‡ªæ´½ï¼ˆä¸å†™æ‰§è¡Œç»†èŠ‚ï¼‰",
      "weak_link": "é—­ç¯ä¸­æœ€è„†å¼±çš„ä¸€ç¯åŠåŸå› ï¼ˆæ¡†æ¶å±‚é¢ï¼‰",
      "revenue_trigger": "å†æ¬¡æ˜ç¡®é’±ä»å“ªæ¥ï¼Œå¹¶æŒ‡æ˜å¯¹åº”çš„éåŠ³åŠ¡ç±»å‹ï¼ˆä¸ƒå¤§ç±»ä¹‹ä¸€æˆ–ç»„åˆï¼‰",
      "risks_and_planB": [
        {{"risk": "å…·ä½“é£é™©1ï¼ˆæ¡†æ¶å±‚é¢ï¼‰", "mitigation": "å¯¹åº”çš„åº”å¯¹æ–¹æ¡ˆï¼ˆæ¡†æ¶å±‚é¢ï¼‰"}},
        {{"risk": "å…·ä½“é£é™©2", "mitigation": "å¯¹åº”çš„åº”å¯¹æ–¹æ¡ˆ"}}
      ],
      "first_step": "æ–¹æ¡ˆçš„å¯åŠ¨åŠ¨ä½œï¼ˆæ¡†æ¶å±‚é¢ï¼‰ï¼Œåœ¨ä»€ä¹ˆåœºåŸŸå¼€å±•ï¼Œä¸ºä»€ä¹ˆå¯è¡Œ",
      "labor_load_estimate": {{
        "hours_per_week": "è®¾è®¡è€…é¢„è®¡æŠ•å…¥å°æ—¶æ•°/å‘¨",
        "level": "è½»åº¦(<5å°æ—¶)/ä¸­åº¦(5-10å°æ—¶)/è¿‡é«˜(>10å°æ—¶)",
        "alternative": "å¦‚ä½•é™ä½åŠ³åŠ¨é‡çš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚å¤–åŒ…/æ¨¡æ¿åŒ–/å…±ç®¡å…¥å£ï¼‰"
      }}
    }}
  ]
}}"""

            # è·å–æ¨¡å‹é…ç½®
            model_config = self.get_model_config('main_analysis')
            logger.info(f"æ¨¡å‹é…ç½®: {model_config}")

            # æ‰“å°prompté•¿åº¦ä¿¡æ¯
            total_prompt = system_prompt + user_content + assistant_prompt
            logger.info(f"===== OpenAI API Request Info =====")
            logger.info(f"Model: {model_config['model']}")
            logger.info(f"Max tokens: {model_config['max_tokens']}")
            logger.info(f"System prompt length: {len(system_prompt)} chars")
            logger.info(f"User content length: {len(user_content)} chars")
            logger.info(
                f"Assistant prompt length: {len(assistant_prompt)} chars")
            logger.info(f"Total prompt length: {len(total_prompt)} chars")
            logger.info(f"===== Full Prompt Content =====")
            logger.info(f"System: {system_prompt[:500]}..." if len(
                system_prompt) > 500 else f"System: {system_prompt}")
            logger.info(f"User: {user_content[:500]}..." if len(user_content) >
                        500 else f"User: {user_content}")
            logger.info(f"Assistant: {assistant_prompt[:500]}..." if len(
                assistant_prompt) > 500 else f"Assistant: {assistant_prompt}")
            logger.info(f"================================")

            # è°ƒç”¨OpenAI APIï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
            logger.info("=== å³å°†è°ƒç”¨_call_openai_with_retry ===")
            try:
                response = self._call_openai_with_retry(
                    model=model_config['model'],
                    messages=[{
                        "role": "system",
                        "content": system_prompt
                    }, {
                        "role": "user",
                        "content": user_content
                    }, {
                        "role": "assistant",
                        "content": assistant_prompt
                    }],
                    response_format={"type": "json_object"},
                    temperature=model_config['temperature'],
                    max_tokens=model_config['max_tokens'],
                    timeout=model_config['timeout'])

                # å¦‚æœå“åº”ä¸ºNoneï¼ˆç½‘ç»œé”™è¯¯ï¼‰ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›å¤‡ç”¨æ–¹æ¡ˆ
                if response is None:
                    logger.error("ğŸ’¥ OpenAI APIè¿”å›Noneï¼Œè¿™é€šå¸¸æ„å‘³ç€è¿æ¥å¤±è´¥")
                    raise ConnectionError("OpenAI APIè¿æ¥å¤±è´¥ï¼Œå“åº”ä¸ºNone")
                    
            except Exception as api_error:
                logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(api_error)}")
                # æŠ›å‡ºè¿æ¥é”™è¯¯è®©ä¸Šå±‚å¤„ç†
                raise ConnectionError(f"OpenAI APIè¿æ¥å¤±è´¥: {str(api_error)}")

            # è§£æå“åº”
            result_text = response.choices[0].message.content
            if not result_text:
                raise ValueError("AIè¿”å›å†…å®¹ä¸ºç©º")
            result = json.loads(result_text)

            # éªŒè¯ç»“æœç»“æ„
            if not self._validate_result_structure(result):
                raise ValueError("AIè¿”å›ç»“æ„ä¸å®Œæ•´")

            return result

        except json.JSONDecodeError as e:
            import traceback
            logger.error(f"ğŸ’¥ JSON parsing error: {e}")
            logger.error(f"ğŸ’¥ Full traceback: {traceback.format_exc()}")
            logger.error(f"ğŸ’¥ AI response text that failed to parse: {result_text[:1000] if 'result_text' in locals() else 'No response text available'}")
            return self._get_fallback_result(form_data)
        except Exception as e:
            import traceback
            logger.error(f"ğŸ’¥ AI generation error: {e}")
            logger.error(f"ğŸ’¥ Error type: {type(e).__name__}")
            logger.error(f"ğŸ’¥ Full traceback: {traceback.format_exc()}")
            logger.error(f"ğŸ’¥ This error caused fallback result to be used instead of real OpenAI analysis")
            return self._get_fallback_result(form_data)

    def refine_path(self, pipeline_data: Dict[str, Any],
                    refinement_data: Dict[str,
                                          Any], db_session) -> Dict[str, Any]:
        """ç»†åŒ–æŒ‡å®šç®¡é“ï¼ˆåŸºäºæœ€æ–°promptè¦æ±‚ï¼‰"""
        try:
            selected_pipeline_id = refinement_data.get(
                'selected_pipeline_id',
                refinement_data.get('selected_path_id'))
            add_personas = refinement_data.get('add_personas', [])
            constraints = refinement_data.get('constraints', '')
            tweaks = refinement_data.get('tweaks', '')

            # æ„é€ å®Œæ•´çš„ç³»ç»Ÿæç¤ºï¼ˆåŸºäºä¸»è¦promptçš„æ ¸å¿ƒåŸåˆ™ï¼‰
            system_prompt = """ä½ æ˜¯"Angela"ï¼Œä¸“ç²¾éåŠ³åŠ¡æ”¶å…¥ç®¡é“è®¾è®¡çš„é«˜çº§å•†ä¸šé¡¾é—®ã€‚ç°åœ¨éœ€è¦ç»†åŒ–ä¼˜åŒ–ä¸€æ¡ç°æœ‰è·¯å¾„ã€‚

ã€æ ¸å¿ƒåŸåˆ™ã€‘
1. éµå¾ªã€æ„è¯†+èƒ½é‡+èƒ½åŠ›=ç»“æœã€‘å…¬å¼
2. ä¸ƒå¤§ç±»å‹ï¼šç§Ÿé‡‘/åˆ©æ¯/è‚¡ä»½/ç‰ˆæƒ/å±…é—´/ä¼ä¸šè¿é”/å›¢é˜Ÿæ”¶ç›Š
3. è®¾è®¡è€…å¿…é¡»ä¸º"ç»Ÿç­¹æ–¹"ï¼Œå…¶ä»–äººç‰©ä¿æŒåŸæœ‰role_type
4. è¾“å‡ºæ¡†æ¶æ€§æ–¹æ¡ˆï¼Œä¸å†™æ‰§è¡Œé¢—ç²’åº¦
5. ä¿æŒæ‰€æœ‰ç”¨æˆ·æä¾›çš„å…³é”®äººç‰©ï¼Œåç§°å®Œå…¨ä¸€è‡´

ã€ä¼˜åŒ–è¦æ±‚ã€‘
- ä¿æŒè·¯å¾„IDä¸å˜
- å®Œå–„framework_logicçš„é€»è¾‘é“¾æ¡
- ä¼˜åŒ–é˜²ç»•è¿‡æœºåˆ¶å’Œæ”¶ç›Šè§¦å‘ç‚¹
- ç¡®ä¿MVPæ›´åŠ å¯è¡Œ
- é™ä½åŠ³åŠ¨é‡ä¼°ç®—"""

            user_content = f"""ã€å½“å‰ç®¡é“ã€‘
{json.dumps(pipeline_data, ensure_ascii=False, indent=2)}

ã€è¡¥å……äººç‰©ã€‘ï¼ˆéœ€è¦æ•´åˆåˆ°parties_structureä¸­ï¼‰
{json.dumps(add_personas, ensure_ascii=False, indent=2)}

ã€çº¦æŸæ¡ä»¶ã€‘
{constraints}

ã€è°ƒæ•´è¦æ±‚ã€‘
{tweaks}

è¯·ä¸¥æ ¼æŒ‰ç…§æœ€æ–°JSONç»“æ„ä¼˜åŒ–è¿™æ¡ç®¡é“ï¼Œé‡ç‚¹å®Œå–„framework_logicã€parties_structureã€MVPå’Œé˜²ç»•è¿‡æœºåˆ¶ã€‚ä¿æŒIDä¸å˜ï¼Œä½†ä¼˜åŒ–å…¶ä»–æ‰€æœ‰å­—æ®µã€‚"""

            # è·å–æ¨¡å‹é…ç½®
            model_config = self.get_model_config('refinement')

            response = self._call_openai_with_retry(
                model=model_config['model'],
                messages=[{
                    "role": "system",
                    "content": system_prompt
                }, {
                    "role": "user",
                    "content": user_content
                }],
                response_format={"type": "json_object"},
                temperature=0.6,
                max_tokens=model_config['max_tokens'],
                timeout=model_config['timeout'])

            # å¦‚æœå“åº”ä¸ºNoneï¼ˆç½‘ç»œé”™è¯¯ï¼‰ï¼Œè¿”å›åŸç®¡é“
            if response is None:
                logger.warning("Pipeline refinement APIè¿”å›Noneï¼Œä¿æŒåŸç®¡é“")
                return pipeline_data

            result_text = response.choices[0].message.content
            if not result_text:
                return pipeline_data

            result = json.loads(result_text)

            # éªŒè¯ç»†åŒ–åçš„ç®¡é“ç»“æ„ï¼ˆç®€åŒ–éªŒè¯ï¼‰
            if not result.get('id') or not result.get('name'):
                logger.warning(
                    "Refined pipeline missing basic fields, returning original"
                )
                return pipeline_data

            return result

        except json.JSONDecodeError as e:
            logger.error(f"Pipeline refinement JSON parsing error: {e}")
            return pipeline_data
        except Exception as e:
            logger.error(f"Pipeline refinement error: {e}")
            # è¿”å›åŸç®¡é“ä½œä¸ºåå¤‡
            return pipeline_data

    def _validate_result_structure(self, result: Dict[str, Any]) -> bool:
        """éªŒè¯è¿”å›ç»“æœçš„ç»“æ„å®Œæ•´æ€§ï¼ˆåŸºäºæœ€æ–°pipelinesç»“æ„ï¼‰"""
        # éªŒè¯é¡¶çº§ç»“æ„
        required_keys = ['overview', 'pipelines']
        if not all(key in result for key in required_keys):
            logger.warning(
                f"Missing top-level keys. Has: {list(result.keys())}, Required: {required_keys}"
            )
            return False

        # éªŒè¯overviewç»“æ„
        overview = result.get('overview', {})
        required_overview_keys = [
            'situation', 'income_type', 'core_insight', 'gaps',
            'suggested_roles_to_hunt'
        ]
        if not all(key in overview for key in required_overview_keys):
            logger.warning(
                f"Overview missing keys. Has: {list(overview.keys())}, Required: {required_overview_keys}"
            )
            return False

        # éªŒè¯pipelinesç»“æ„
        pipelines = result.get('pipelines', [])
        if not pipelines:
            logger.warning("No pipelines found")
            return False

        for i, pipeline in enumerate(pipelines):
            # éªŒè¯pipelineçš„å¿…éœ€å­—æ®µï¼ˆåŸºäºæ–°çš„promptç»“æ„ï¼‰
            required_pipeline_keys = [
                'id', 'name', 'income_mechanism', 'parties_structure',
                'framework_logic', 'mvp', 'weak_link', 'revenue_trigger',
                'risks_and_planB', 'first_step', 'labor_load_estimate'
            ]
            if not all(key in pipeline for key in required_pipeline_keys):
                logger.warning(
                    f"Pipeline {i} missing required keys. Has: {list(pipeline.keys())}, Required: {required_pipeline_keys}"
                )
                return False

            # éªŒè¯income_mechanismç»“æ„
            income_mechanism = pipeline.get('income_mechanism', {})
            if not all(key in income_mechanism
                       for key in ['type', 'trigger', 'settlement']):
                logger.warning(f"Pipeline {i} income_mechanism incomplete")
                return False

            # éªŒè¯parties_structureç»“æ„
            parties = pipeline.get('parties_structure', [])
            if not parties:
                logger.warning(f"Pipeline {i} has empty parties_structure")
                return False

            # éªŒè¯æ¯ä¸ªå‚ä¸æ–¹çš„ç»“æ„
            for j, party in enumerate(parties):
                required_party_keys = [
                    'party', 'role_type', 'resources', 'role_value',
                    'make_them_happy'
                ]
                if not all(key in party for key in required_party_keys):
                    logger.warning(
                        f"Pipeline {i} party {j} missing keys. Has: {list(party.keys())}, Required: {required_party_keys}"
                    )
                    return False

                # éªŒè¯role_typeå€¼
                valid_role_types = ['éœ€æ±‚æ–¹', 'äº¤ä»˜æ–¹', 'èµ„é‡‘æ–¹', 'ç»Ÿç­¹æ–¹']
                if party.get('role_type') not in valid_role_types:
                    logger.warning(
                        f"Pipeline {i} party {j} has invalid role_type: {party.get('role_type')}"
                    )
                    return False

            # éªŒè¯framework_logicç»“æ„
            framework_logic = pipeline.get('framework_logic', {})
            required_framework_keys = [
                'resource_chain', 'motivation_match', 'designer_position',
                'designer_income'
            ]
            if not all(key in framework_logic
                       for key in required_framework_keys):
                logger.warning(f"Pipeline {i} framework_logic incomplete")
                return False

            # éªŒè¯labor_load_estimateç»“æ„
            labor_load = pipeline.get('labor_load_estimate', {})
            if not all(key in labor_load
                       for key in ['hours_per_week', 'level', 'alternative']):
                logger.warning(f"Pipeline {i} labor_load_estimate incomplete")
                return False

        return True

    def _get_fallback_result(self, form_data: Dict[str,
                                                   Any]) -> Dict[str, Any]:
        """é™çº§è¿”å›ç»“æœï¼ˆå½“AIè°ƒç”¨å¤±è´¥æ—¶ï¼‰- åŸºäºæœ€æ–°promptè¦æ±‚çš„å®Œæ•´ç»“æ„"""
        project_name = form_data.get('projectName', 'é¡¹ç›®')
        project_description = form_data.get('projectDescription', '')
        key_persons = form_data.get('keyPersons', [])

        # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……è§’è‰²
        needs_additional_roles = len(key_persons) < 2  # ç®€å•è§„åˆ™ï¼šå°‘äº2ä¸ªäººç‰©æ—¶å»ºè®®è¡¥å……
        
        # åˆ†æç°æœ‰äººç‰©çš„è§’è‰²ç±»å‹åˆ†å¸ƒ
        existing_role_types = set()
        for person in key_persons:
            original_role = person.get('role', '')
            if original_role:
                role_type = self.get_role_type_by_identifier(original_role)
                existing_role_types.add(role_type)
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å…³é”®è§’è‰²ç±»å‹
        required_types = {'éœ€æ±‚æ–¹', 'äº¤ä»˜æ–¹'}
        missing_types = required_types - existing_role_types
        if missing_types:
            needs_additional_roles = True

        # æ„å»ºå‚ä¸æ–¹ç»“æ„ï¼ˆä¿ç•™æ‰€æœ‰ç”¨æˆ·è¾“å…¥çš„å…³é”®äººç‰©ï¼‰
        parties_structure = [{
            "party":
            "è®¾è®¡è€…ï¼ˆä½ ï¼‰",
            "role_type":
            "ç»Ÿç­¹æ–¹",
            "resources": ["ç»Ÿç­¹åè°ƒèƒ½åŠ›", "è§„åˆ™åˆ¶å®š", "åˆä½œä¼™ä¼´ç­›é€‰æ ‡å‡†", "ç»“ç®—ç®¡ç†"],
            "role_value":
            "ä½œä¸ºè¿æ¥å™¨å’Œè§„åˆ™åˆ¶å®šè€…ï¼Œç¡®ä¿å„æ–¹åˆä½œé¡ºç•…ï¼Œæ§åˆ¶æ ¸å¿ƒç¯èŠ‚",
            "make_them_happy":
            "é€šè¿‡æ’®åˆæœåŠ¡è·å¾—ç¨³å®šçš„éåŠ³åŠ¡æ”¶å…¥ï¼Œå»ºç«‹å¯æŒç»­çš„å•†ä¸šç®¡é“"
        }]

        # ä¸ºæ¯ä¸ªå…³é”®äººç‰©åˆ†é…åˆé€‚çš„role_type
        role_type_mapping = {
            0: "éœ€æ±‚æ–¹",  # ç¬¬ä¸€ä¸ªäººç‰©é»˜è®¤ä¸ºéœ€æ±‚æ–¹
            1: "äº¤ä»˜æ–¹",  # ç¬¬äºŒä¸ªäººç‰©é»˜è®¤ä¸ºäº¤ä»˜æ–¹
        }

        for i, person in enumerate(key_persons):
            name = person.get('name', f'å…³é”®äººç‰©{i+1}')
            resources = person.get('resources', ['ä¸“ä¸šæŠ€èƒ½', 'å®¢æˆ·åŸºç¡€'])
            make_happy = person.get('make_happy', ['è·å¾—æ”¶ç›Š', 'æ‰©å±•ä¸šåŠ¡'])
            
            # å¦‚æœæœ‰åŸå§‹roleä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨roleç±»å‹åˆ¤æ–­ï¼Œå¦åˆ™ä½¿ç”¨ç´¢å¼•æ˜ å°„
            original_role = person.get('role', '')
            if original_role:
                role_type = self.get_role_type_by_identifier(original_role)
            else:
                role_type = role_type_mapping.get(i, "äº¤ä»˜æ–¹")  # è¶…è¿‡2ä¸ªçš„é»˜è®¤ä¸ºäº¤ä»˜æ–¹

            parties_structure.append({
                "party":
                name,
                "role_type":
                role_type,
                "resources":
                resources if resources else ["ä¸“ä¸šèƒ½åŠ›", "å®¢æˆ·èµ„æº"],
                "role_value":
                f"åœ¨é—­ç¯ä¸­æä¾›{role_type}çš„æ ¸å¿ƒä»·å€¼ï¼Œç¡®ä¿æœåŠ¡è´¨é‡å’Œå®¢æˆ·æ»¡æ„åº¦",
                "make_them_happy":
                self.format_make_happy(make_happy)
            })

        # æ·»åŠ å¾…è¡¥é½è§’è‰²ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if needs_additional_roles and missing_types:
            for missing_type in missing_types:
                role_name_mapping = {
                    "éœ€æ±‚æ–¹": "æ¸ é“å®¢æˆ·æº",
                    "äº¤ä»˜æ–¹": "ä¸“ä¸šæœåŠ¡æ–¹",
                    "èµ„é‡‘æ–¹": "æŠ•èµ„åˆä½œæ–¹"
                }
                role_name = role_name_mapping.get(missing_type, "åˆä½œä¼™ä¼´")
                
                parties_structure.append({
                    "party": f"ã€å¾…è¡¥é½ã€‘{role_name}",
                    "role_type": missing_type,
                    "resources": ["å¾…ç¡®å®šçš„å…³é”®èµ„æº", "å¾…åŒ¹é…çš„åˆä½œèƒ½åŠ›"],
                    "role_value": f"è¡¥é½{missing_type}è§’è‰²ï¼Œå®Œå–„é—­ç¯ç»“æ„ï¼Œç¡®ä¿ç®¡é“å¯æŒç»­è¿è¡Œ",
                    "make_them_happy": "é€šè¿‡äº’åˆ©å…±èµ¢çš„åˆä½œæ¨¡å¼ï¼Œå®ç°å„æ–¹ä»·å€¼æœ€å¤§åŒ–"
                })

        return {
            "overview": {
                "situation":
                f"åŸºäºã€æ„è¯†+èƒ½é‡+èƒ½åŠ›=ç»“æœã€‘å…¬å¼åˆ†æï¼š{project_name}å…·å¤‡åˆæ­¥èµ„æºåŸºç¡€ï¼Œè®¾è®¡è€…ä½œä¸ºç»Ÿç­¹æ–¹æ•´åˆç°æœ‰å…³é”®äººç‰©èµ„æºï¼Œæ„å»ºæ’®åˆå‹éåŠ³åŠ¡æ”¶å…¥ç®¡é“ã€‚æ„è¯†æ¥è‡ªè®¾è®¡è€…çš„è§„åˆ™è®¾è®¡ï¼Œèƒ½é‡æ¥è‡ªå…³é”®äººç‰©çš„ç§¯æå‚ä¸ï¼Œèƒ½åŠ›å€Ÿç”¨å„æ–¹ä¸“ä¸šèµ„æºã€‚",
                "income_type":
                "å±…é—´ï¼ˆæ’®åˆè´¹/ä¸­ä»‹è´¹ï¼‰",
                "core_insight":
                "åˆ©ç”¨ç°æœ‰å…³é”®äººç‰©çš„ä¸“ä¸šèƒ½åŠ›å’Œå®¢æˆ·åŸºç¡€ï¼Œè®¾è®¡è€…ä½œä¸ºç»Ÿç­¹æ–¹åˆ¶å®šåˆä½œè§„åˆ™å’Œè´¨é‡æ ‡å‡†ï¼Œé€šè¿‡æ’®åˆæœåŠ¡å»ºç«‹æŒç»­çš„éåŠ³åŠ¡æ”¶å…¥ç®¡é“ï¼Œå…³é”®åœ¨äºé˜²ç»•è¿‡æœºåˆ¶å’Œå…±ç®¡ç»“ç®—ã€‚",
                "gaps": ["æ˜ç¡®åˆä½œç»†åˆ™", "å»ºç«‹é˜²ç»•è¿‡æœºåˆ¶"]
                if not needs_additional_roles else ["è¡¥å……æ¸ é“èµ„æºæ–¹", "å»ºç«‹åˆä½œæ ‡å‡†"],
                "suggested_roles_to_hunt":
                [] if not needs_additional_roles else [{
                    "role":
                    "æ¸ é“èµ„æºæ–¹",
                    "role_type":
                    "éœ€æ±‚æ–¹",
                    "why":
                    "éœ€è¦æµé‡å…¥å£å’Œå®¢æˆ·è·å–æ¸ é“ï¼Œç¡®ä¿ä¸šåŠ¡å¯æŒç»­å‘å±•",
                    "where_to_find":
                    "è¡Œä¸šåä¼šã€å•†ä¼šã€åŒåŸä¼ä¸šå®¶ç¾¤ã€ç›¸å…³ä¸šåŠ¡çš„æœ‹å‹åœˆ",
                    "outreach_script":
                    "æˆ‘ä»¬æœ‰ä¼˜è´¨çš„æœåŠ¡å›¢é˜Ÿå’Œæˆç†Ÿçš„ç®¡ç†ç»éªŒï¼Œæ­£åœ¨å¯»æ±‚ä¼˜è´¨åˆä½œä¼™ä¼´æ‰©å¤§ä¸šåŠ¡è¦†ç›–ï¼ŒæœŸå¾…ä¸æ‚¨æ¢è®¨åŒèµ¢åˆä½œæœºä¼š"
                }]
            },
            "pipelines": [{
                "id":
                "pipeline_1",
                "name":
                f"{project_name}æ’®åˆæœåŠ¡ç®¡é“",
                "income_mechanism": {
                    "type": "å±…é—´ï¼ˆæ’®åˆè´¹ï¼‰",
                    "trigger": "æ¯æ¬¡æˆåŠŸåŒ¹é…å¹¶å®Œæˆäº¤æ˜“æ—¶",
                    "settlement": "æŒ‰äº¤æ˜“é‡‘é¢çš„ç™¾åˆ†æ¯”æ”¶å–æˆ–å›ºå®šæ’®åˆè´¹"
                },
                "parties_structure":
                parties_structure,
                "framework_logic": {
                    "resource_chain":
                    "é€šè¿‡æ•´åˆå„æ–¹èµ„æºå½¢æˆä¾›éœ€åŒ¹é…é—­ç¯ï¼šéœ€æ±‚æ–¹æä¾›å®¢æˆ·å’Œéœ€æ±‚ä¿¡æ¯ï¼Œäº¤ä»˜æ–¹æä¾›ä¸“ä¸šæœåŠ¡èƒ½åŠ›ï¼Œè®¾è®¡è€…åˆ¶å®šåŒ¹é…è§„åˆ™å’Œè´¨é‡æ ‡å‡†ï¼Œç¡®ä¿äº¤æ˜“é¡ºåˆ©å®Œæˆ",
                    "motivation_match":
                    "éœ€æ±‚æ–¹è·å¾—ä¼˜è´¨æœåŠ¡è§£å†³æ–¹æ¡ˆï¼Œäº¤ä»˜æ–¹è·å¾—ç¨³å®šå®¢æˆ·æ¥æºï¼Œè®¾è®¡è€…é€šè¿‡æ’®åˆè·å¾—æŒç»­æ”¶ç›Šï¼Œå½¢æˆä¸‰æ–¹å…±èµ¢æ ¼å±€",
                    "designer_position":
                    "æ§åˆ¶å®¢æˆ·ç­›é€‰æ ‡å‡†ã€æœåŠ¡æä¾›å•†è®¤è¯ä½“ç³»ã€äº¤æ˜“æµç¨‹è§„èŒƒå’Œç»“ç®—ç¯èŠ‚ï¼Œç¡®ä¿æ‰€æœ‰äº¤æ˜“å¿…é¡»é€šè¿‡ç»Ÿç­¹æ–¹å®Œæˆ",
                    "designer_income":
                    "å±…é—´æ”¶ç›Š - é€šè¿‡åˆ¶å®šè§„åˆ™å’Œæ§åˆ¶å…³é”®ç¯èŠ‚è·å¾—æ¯ç¬”äº¤æ˜“çš„æ’®åˆè´¹ç”¨"
                },
                "mvp":
                "å»ºç«‹ç®€å•çš„ä¾›éœ€ä¿¡æ¯æ”¶é›†å’ŒåŒ¹é…æœºåˆ¶ï¼Œå…ˆä»ç°æœ‰äººè„‰å¼€å§‹å°è§„æ¨¡æ’®åˆï¼ŒéªŒè¯å•†ä¸šæ¨¡å¼å¯è¡Œæ€§åé€æ­¥æ‰©å¤§è§„æ¨¡ã€‚",
                "weak_link":
                "åˆæœŸå¯èƒ½é¢ä¸´ä¾›éœ€åŒæ–¹ä¿¡ä»»å»ºç«‹çš„æŒ‘æˆ˜ï¼Œéœ€è¦é€šè¿‡æˆåŠŸæ¡ˆä¾‹å’Œå£ç¢‘ç§¯ç´¯æ¥å¼ºåŒ–å¹³å°å¯ä¿¡åº¦ã€‚",
                "revenue_trigger":
                "å±…é—´æ”¶ç›Šï¼šæ¯æ¬¡æˆåŠŸæ’®åˆäº¤æ˜“æ—¶æŒ‰æ¯”ä¾‹æˆ–å›ºå®šè´¹ç”¨æ”¶å–æ’®åˆè´¹",
                "risks_and_planB": [{
                    "risk": "ä¾›éœ€åŒæ–¹ç»•è¿‡å¹³å°ç›´æ¥åˆä½œ",
                    "mitigation": "å»ºç«‹ç‹¬å®¶åˆä½œåè®®ï¼Œæ§åˆ¶å…³é”®å®¢æˆ·ä¿¡æ¯ï¼Œè®¾è®¡é˜¶æ¢¯å¼å¥–åŠ±æœºåˆ¶"
                }, {
                    "risk": "ç«äº‰å¯¹æ‰‹è¿›å…¥å¸‚åœº",
                    "mitigation": "å»ºç«‹å·®å¼‚åŒ–æœåŠ¡æ ‡å‡†ï¼Œæ·±è€•ç»†åˆ†é¢†åŸŸï¼Œæé«˜è½¬æ¢æˆæœ¬"
                }],
                "first_step":
                "ä»ç°æœ‰äººè„‰ä¸­è¯†åˆ«2-3ä¸ªæ½œåœ¨çš„éœ€æ±‚æ–¹å’Œäº¤ä»˜æ–¹ï¼Œè®¾è®¡åˆæ­¥çš„åˆä½œè§„åˆ™å’Œè´¹ç”¨æ ‡å‡†ï¼Œå®‰æ’è¯•ç‚¹æ’®åˆé¡¹ç›®éªŒè¯æ¨¡å¼",
                "labor_load_estimate": {
                    "hours_per_week": "5-8å°æ—¶",
                    "level": "ä¸­åº¦",
                    "alternative":
                    "å»ºç«‹æ ‡å‡†åŒ–çš„ç­›é€‰å’ŒåŒ¹é…æµç¨‹ï¼ŒåŸ¹è®­åŠ©æ‰‹å¤„ç†æ—¥å¸¸å¯¹æ¥å·¥ä½œï¼Œè®¾è®¡è‡ªåŠ¨åŒ–çš„ä¿¡æ¯æ”¶é›†å’Œåˆæ­¥ç­›é€‰ç³»ç»Ÿ"
                }
            }]
        }