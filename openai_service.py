import os
import json
import logging
import ssl
import time
from openai import OpenAI
from typing import Dict, List, Any, Optional

# OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–
# the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
# do not change this unless explicitly requested by the user
import httpx

# åˆ›å»ºå¸¦ä¼˜åŒ–è¿æ¥é…ç½®çš„å®¢æˆ·ç«¯ - ä½¿ç”¨laozhang.aiä¸­è½¬API
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    base_url="https://api.laozhang.ai/v1",  # ä½¿ç”¨ä¸­è½¬API
    timeout=httpx.Timeout(120.0, connect=30.0),  # å¢åŠ è¶…æ—¶ï¼šè¿æ¥30ç§’ï¼Œè¯»å–120ç§’
    http_client=httpx.Client(limits=httpx.Limits(max_connections=10,
                                                 max_keepalive_connections=5),
                             timeout=httpx.Timeout(120.0, connect=30.0)))

logger = logging.getLogger(__name__)


class AngelaAI:
    """Angela - éåŠ³åŠ¡æ”¶å…¥ç®¡é“è®¾è®¡AIæœåŠ¡"""

    def __init__(self):
        self.default_model = "gpt-4o"  # é»˜è®¤æ¨¡å‹
        self.default_max_tokens = 2500  # é»˜è®¤tokenæ•°é‡
        
    def load_prompt_from_file(self, prompt_type: str) -> str:
        """ä»æ–‡ä»¶åŠ è½½prompt"""
        try:
            if prompt_type == 'system':
                file_path = 'prompts/system_prompt.txt'
            elif prompt_type == 'assistant':
                file_path = 'prompts/assistant_prompt.txt'
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„promptç±»å‹: {prompt_type}")
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            logger.info(f"æˆåŠŸåŠ è½½{prompt_type} promptï¼Œé•¿åº¦: {len(content)}å­—ç¬¦")
            return content
        except Exception as e:
            logger.error(f"åŠ è½½{prompt_type} promptå¤±è´¥: {e}")
            # è¿”å›å¤‡ç”¨prompt
            if prompt_type == 'system':
                return "ä½ æ˜¯Angelaï¼Œä¸“ä¸šçš„éåŠ³åŠ¡æ”¶å…¥è·¯å¾„è®¾è®¡å¸ˆã€‚"
            else:
                return "ç°åœ¨æˆ‘å°†ä¸ºä½ åˆ†æè¿™ä¸ªé¡¹ç›®çš„éåŠ³åŠ¡æ”¶å…¥è®¾è®¡æ–¹æ¡ˆã€‚"

    def get_model_config(self, config_type='main_analysis'):
        """ä»æ•°æ®åº“è·å–æ¨¡å‹é…ç½®"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
            import importlib
            models_module = importlib.import_module('models')
            ModelConfig = getattr(models_module, 'ModelConfig')
            config = ModelConfig.get_config(config_type, self.default_model)
            return config
        except Exception as e:
            logger.warning(f"Failed to get model config: {e}, using defaults")
            return {
                'model': self.default_model,
                'temperature': 0.7,
                'max_tokens': self.default_max_tokens,
                'timeout': 45
            }

    def _call_openai_with_retry(self, **kwargs):
        """è°ƒç”¨OpenAI APIï¼Œå¸¦å¼ºåŒ–é‡è¯•æœºåˆ¶"""
        logger.info("=== _call_openai_with_retryæ–¹æ³•è¢«è°ƒç”¨ ===")
        logger.info(
            f"ä¼ å…¥å‚æ•°: model={kwargs.get('model')}, timeout={kwargs.get('timeout')}"
        )
        max_retries = 3  # å¢åŠ é‡è¯•æ¬¡æ•°æé«˜æˆåŠŸç‡
        for attempt in range(max_retries):
            try:
                logger.info(
                    f"æ­£åœ¨è°ƒç”¨OpenAI API (å°è¯• {attempt + 1}/{max_retries})...")

                # ä¸ºæ¯æ¬¡é‡è¯•åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯è¿æ¥ï¼Œæå‡SSLè¿æ¥ç¨³å®šæ€§
                if attempt > 0:
                    # ä½¿ç”¨æ›´ä¿å®ˆçš„è¶…æ—¶è®¾ç½®
                    fresh_client = OpenAI(
                        api_key=os.environ.get("OPENAI_API_KEY"),
                        base_url="https://api.laozhang.ai/v1",  # ä½¿ç”¨ä¸­è½¬API
                        timeout=httpx.Timeout(150.0, connect=45.0, read=150.0)  # è¿›ä¸€æ­¥å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œæå‡ç¨³å®šæ€§
                    )
                    response = fresh_client.chat.completions.create(**kwargs)
                    logger.info("âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
                    return response
                else:
                    response = client.chat.completions.create(**kwargs)
                    logger.info("âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
                    return response

            except (httpx.TimeoutException, httpx.ConnectError,
                    ConnectionError, httpx.ReadTimeout, httpx.ConnectTimeout,
                    TimeoutError, OSError, ConnectionResetError,
                    BrokenPipeError, ssl.SSLError, ssl.SSLEOFError) as e:
                if attempt < max_retries - 1:
                    wait_time = 2 * (attempt + 1)  # ç¼©çŸ­ç­‰å¾…æ—¶é—´: 2s, 4s
                    logger.warning(
                        f"OpenAI APIç½‘ç»œè¶…æ—¶ (å°è¯• {attempt + 1}): {str(e)}, {wait_time}ç§’åé‡è¯•..."
                    )
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"OpenAI APIç½‘ç»œè¶…æ—¶ï¼Œæœ€ç»ˆå¤±è´¥: {str(e)}")
                    # ç½‘ç»œè¿æ¥é—®é¢˜ï¼ŒæŠ›å‡ºå‹å¥½çš„é”™è¯¯ä¿¡æ¯
                    raise ConnectionError("OpenAI APIç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
            except Exception as e:
                import traceback
                logger.error(f"ğŸ’¥ OpenAI APIè°ƒç”¨é‡åˆ°å…¶ä»–é”™è¯¯: {str(e)}")
                logger.error(f"ğŸ’¥ é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"ğŸ’¥ å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
                logger.error(f"ğŸ’¥ ä¼ å…¥çš„å‚æ•°: {kwargs}")
                raise e

    def format_role_to_chinese(self, role_identifier: str) -> str:
        """å°†è‹±æ–‡è§’è‰²æ ‡è¯†ç¬¦è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤º"""
        role_mapping = {
            # éœ€æ±‚æ–¹è§’è‰²
            'enterprise_owner': 'ä¼ä¸šä¸»',
            'store_owner': 'å®ä½“åº—ä¸»',
            'department_head': 'éƒ¨é—¨è´Ÿè´£äºº',
            'brand_manager': 'ä¸»ç†äºº',
            # äº¤ä»˜æ–¹è§’è‰²
            'product_provider': 'äº§å“æ–¹',
            'service_provider': 'æœåŠ¡æ–¹',
            'traffic_provider': 'æµé‡æ–¹',
            'other_provider': 'å…¶ä»–èµ„æºæ–¹'
        }
        return role_mapping.get(role_identifier, role_identifier)

    def get_role_type_by_identifier(self, role_identifier: str) -> str:
        """æ ¹æ®è§’è‰²æ ‡è¯†ç¬¦è·å–è§’è‰²ç±»å‹ï¼ˆéœ€æ±‚æ–¹/äº¤ä»˜æ–¹ç­‰ï¼‰"""
        demand_roles = [
            'enterprise_owner', 'store_owner', 'department_head',
            'brand_manager'
        ]
        delivery_roles = [
            'product_provider', 'service_provider', 'traffic_provider',
            'other_provider'
        ]

        if role_identifier in demand_roles:
            return 'éœ€æ±‚æ–¹'
        elif role_identifier in delivery_roles:
            return 'äº¤ä»˜æ–¹'
        else:
            return 'å…¶ä»–æ–¹'

    def format_make_happy(self, make_happy_data) -> str:
        """æ ¼å¼åŒ–åŠ¨æœºæ ‡ç­¾æ•°æ®"""
        if not make_happy_data:
            return "æœªæŒ‡å®š"

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆåˆ†å‰²æˆåˆ—è¡¨
        if isinstance(make_happy_data, str):
            make_happy_list = make_happy_data.split(',')
        else:
            make_happy_list = make_happy_data

        # æ˜ å°„å€¼åˆ°æ˜¾ç¤ºæ–‡æœ¬ï¼ˆåŒ…å«æ–°çš„å®é™…æ ‡ç­¾ï¼‰
        label_map = {
            'recognition': 'è·å¾—è®¤å¯/åå£°',
            'learning': 'å­¦ä¹ æ–°çŸ¥è¯†/æŠ€èƒ½',
            'networking': 'æ‰©å±•äººè„‰/ç¤¾äº¤åœˆ',
            'fun': 'å¨±ä¹æ”¾æ¾/äº«å—è¿‡ç¨‹',
            'helping': 'å¸®åŠ©ä»–äºº/ç¤¾ä¼šä»·å€¼',
            'money': 'è·å¾—é‡‘é’±/ç»æµæ”¶ç›Š',
            'power': 'è·å¾—æƒåŠ›/å½±å“åŠ›',
            'creation': 'åˆ›é€ ä½œå“/è¡¨è¾¾è‡ªæˆ‘',
            'growth': 'ä¸ªäººæˆé•¿/çªç ´æŒ‘æˆ˜',
            # æ–°å¢å®é™…ä½¿ç”¨çš„æ ‡ç­¾
            'bring_leads': 'å¸¦æ¥å®¢æˆ·/å¼•æµ',
            'recurring_income': 'è·å¾—æŒç»­æ”¶å…¥',
            'no_conflict_current_partner': 'ä¸å†²çªç°æœ‰åˆä½œ',
            'brand_exposure': 'å“ç‰Œæ›å…‰',
            'expand_network': 'æ‹“å±•ç½‘ç»œ/äººè„‰'
        }

        return "ã€".join([
            label_map.get(item.strip(), item.strip())
            for item in make_happy_list
        ])

    def get_core_knowledge_fallback(self) -> str:
        """å½“çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥æ—¶çš„æ ¸å¿ƒçŸ¥è¯†è¦ç‚¹"""
        return """â€¢ éåŠ³åŠ¡æ”¶å…¥æ ¸å¿ƒå…¬å¼ï¼šæ„è¯†+èƒ½é‡+èƒ½åŠ›ï¼ˆè¡ŒåŠ¨ï¼‰=ç»“æœ
â€¢ ä¸ƒå¤§ç±»å‹ï¼šç§Ÿé‡‘ï¼ˆä¸‡ç‰©çš†å¯ç§Ÿï¼‰ã€åˆ©æ¯ã€è‚¡ä»½/çº¢åˆ©ã€ç‰ˆæƒã€ä¸“åˆ©ã€ä¼ä¸šè¿é”ã€å›¢é˜Ÿæ”¶ç›Š
â€¢ ä¸‰æ­¥æ³•åˆ™ï¼šç›˜èµ„æºâ†’æ­ç®¡é“â†’åŠ¨çœŸæ ¼
â€¢ æ ¸å¿ƒåŸåˆ™ï¼šè®©å…³é”®ç¯èŠ‚çš„å…³é”®äººç‰©éƒ½é«˜å…´ï¼Œä¸¥æ ¼åŒºåˆ†éœ€æ¢å–çš„äººç‰©èµ„æºvså¯ç›´æ¥åŠ¨ç”¨çš„å¤–éƒ¨èµ„æº
â€¢ æˆåŠŸè¦ç´ ï¼š1)è®¾è®¡å…±èµ¢æœºåˆ¶ 2)æŒæ¡æ ¸å¿ƒä¿¡æ¯+ç­›é€‰è§„åˆ™ 3)å‰ç½®åˆä½œè§„åˆ™"""

    def generate_income_paths(self, form_data: Dict[str, Any],
                              db_session) -> Dict[str, Any]:
        """ç”ŸæˆéåŠ³åŠ¡æ”¶å…¥è·¯å¾„"""
        logger.info("=== Angela AI generate_income_pathsæ–¹æ³•å¼€å§‹ ===")
        logger.info(f"è¾“å…¥æ•°æ®: {json.dumps(form_data, ensure_ascii=False)}")
        try:
            # æå–è¡¨å•æ•°æ®
            project_name = form_data.get('projectName', 'æœªå‘½åé¡¹ç›®')
            project_description = form_data.get('projectDescription', '')
            key_persons = form_data.get('keyPersons', [])
            external_resources = form_data.get('externalResources', [])

            # ä»æ–‡ä»¶åŠ è½½system promptå’Œassistant prompt
            system_prompt = self.load_prompt_from_file('system')
            assistant_prompt_prefix = self.load_prompt_from_file('assistant')

            # æ„é€ ç”¨æˆ·æç¤º
            user_content = f"""ã€é¡¹ç›®åç§°ã€‘{project_name}
ã€é¡¹ç›®èƒŒæ™¯ã€‘{project_description}

ã€å…³é”®äººç‰©ã€‘ï¼ˆå«è§’è‰²ã€èµ„æºã€åŠ¨æœºï¼‰"""

            for i, person in enumerate(key_persons):
                name = person.get('name', f'äººç‰©{i+1}')
                role = person.get('role', '')  # ä¿®æ­£ï¼šä½¿ç”¨roleè€Œä¸æ˜¯roles
                resources = person.get('resources', [])
                make_happy = person.get('make_happy',
                                        '')  # ä¿®æ­£ï¼šä½¿ç”¨make_happyè€Œä¸æ˜¯makeHappy
                notes = person.get('notes', '')

                # å°†è‹±æ–‡è§’è‰²æ ‡è¯†ç¬¦è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤ºåç§°
                role_chinese = self.format_role_to_chinese(
                    role) if role else "æœªæŒ‡å®š"
                role_type = self.get_role_type_by_identifier(
                    role) if role else "å…¶ä»–æ–¹"

                user_content += f"""
- äººç‰©ï¼š{name}ï½œè§’è‰²ï¼š{role_chinese}ï¼ˆ{role_type}ï¼‰
  èµ„æºï¼š{", ".join(resources) if resources else "æ— "}
  åŠ¨æœºæ ‡ç­¾ï¼ˆå¦‚ä½•è®©TAé«˜å…´ï¼‰ï¼š{self.format_make_happy(make_happy)}
  å¤‡æ³¨ï¼š{notes if notes else "æ— "}"""

            # æ„å»ºå…³é”®äººç‰©åˆ—è¡¨ç”¨äºæç¤º
            key_persons_names = ', '.join([
                person.get('name', f'äººç‰©{i+1}')
                for i, person in enumerate(key_persons)
            ])

            # ä½¿ç”¨ä»æ–‡ä»¶åŠ è½½çš„assistant prompt
            assistant_prompt = assistant_prompt_prefix

            # è·å–æ¨¡å‹é…ç½®
            model_config = self.get_model_config('main_analysis')
            logger.info(f"æ¨¡å‹é…ç½®: {model_config}")

            # æ‰“å°prompté•¿åº¦ä¿¡æ¯
            total_prompt = system_prompt + user_content + assistant_prompt
            logger.info(f"===== OpenAI API Request Info =====")
            logger.info(f"Model: {model_config['model']}")
            logger.info(f"Max tokens: {model_config['max_tokens']}")
            logger.info(f"System prompt length: {len(system_prompt)} chars")
            logger.info(f"User content length: {len(user_content)} chars")
            logger.info(
                f"Assistant prompt length: {len(assistant_prompt)} chars")
            logger.info(f"Total prompt length: {len(total_prompt)} chars")
            logger.info(f"===== Full Prompt Content =====")
            logger.info(f"System: {system_prompt[:500]}..." if len(
                system_prompt) > 500 else f"System: {system_prompt}")
            logger.info(f"User: {user_content[:500]}..." if len(user_content) >
                        500 else f"User: {user_content}")
            logger.info(f"Assistant: {assistant_prompt[:500]}..." if len(
                assistant_prompt) > 500 else f"Assistant: {assistant_prompt}")
            logger.info(f"================================")

            # è°ƒç”¨OpenAI APIï¼Œå¸¦é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
            logger.info("=== å³å°†è°ƒç”¨_call_openai_with_retry ===")
            try:
                response = self._call_openai_with_retry(
                    model=model_config['model'],
                    messages=[{
                        "role": "system",
                        "content": system_prompt
                    }, {
                        "role": "user",
                        "content": user_content
                    }, {
                        "role": "assistant",
                        "content": assistant_prompt
                    }],
                    response_format={"type": "json_object"},
                    temperature=model_config['temperature'],
                    max_tokens=model_config['max_tokens'],
                    timeout=model_config['timeout'])

                # å¦‚æœå“åº”ä¸ºNoneï¼ˆç½‘ç»œé”™è¯¯ï¼‰ï¼ŒæŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›å¤‡ç”¨æ–¹æ¡ˆ
                if response is None:
                    logger.error("ğŸ’¥ OpenAI APIè¿”å›Noneï¼Œè¿™é€šå¸¸æ„å‘³ç€è¿æ¥å¤±è´¥")
                    raise ConnectionError("OpenAI APIè¿æ¥å¤±è´¥ï¼Œå“åº”ä¸ºNone")

            except Exception as api_error:
                logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(api_error)}")
                # æŠ›å‡ºè¿æ¥é”™è¯¯è®©ä¸Šå±‚å¤„ç†
                raise ConnectionError(f"OpenAI APIè¿æ¥å¤±è´¥: {str(api_error)}")

            # è§£æå“åº”
            result_text = response.choices[0].message.content
            if not result_text:
                raise ValueError("AIè¿”å›å†…å®¹ä¸ºç©º")
            result = json.loads(result_text)

            # éªŒè¯ç»“æœç»“æ„
            if not self._validate_result_structure(result):
                raise ValueError("AIè¿”å›ç»“æ„ä¸å®Œæ•´")

            return result

        except json.JSONDecodeError as e:
            import traceback
            logger.error(f"ğŸ’¥ JSON parsing error: {e}")
            logger.error(f"ğŸ’¥ Full traceback: {traceback.format_exc()}")
            # å°è¯•è®°å½•å“åº”æ–‡æœ¬
            logger.error("ğŸ’¥ AI response parsing failed - checking for response content")
            return self._get_fallback_result(form_data)
        except Exception as e:
            import traceback
            logger.error(f"ğŸ’¥ AI generation error: {e}")
            logger.error(f"ğŸ’¥ Error type: {type(e).__name__}")
            logger.error(f"ğŸ’¥ Full traceback: {traceback.format_exc()}")
            logger.error(
                f"ğŸ’¥ This error caused fallback result to be used instead of real OpenAI analysis"
            )
            return self._get_fallback_result(form_data)

    def _validate_result_structure(self, result: Dict[str, Any]) -> bool:
        """éªŒè¯è¿”å›ç»“æœçš„ç»“æ„å®Œæ•´æ€§ï¼ˆåŸºäºæœ€æ–°pipelinesç»“æ„ï¼‰"""
        # éªŒè¯é¡¶çº§ç»“æ„
        required_keys = ['overview', 'pipelines']
        if not all(key in result for key in required_keys):
            logger.warning(
                f"Missing top-level keys. Has: {list(result.keys())}, Required: {required_keys}"
            )
            return False

        # éªŒè¯overviewç»“æ„
        overview = result.get('overview', {})
        required_overview_keys = [
            'situation', 'core_insight', 'gaps',
            'suggested_roles_to_hunt'
        ]
        if not all(key in overview for key in required_overview_keys):
            logger.warning(
                f"Overview missing keys. Has: {list(overview.keys())}, Required: {required_overview_keys}"
            )
            return False

        # éªŒè¯pipelinesç»“æ„
        pipelines = result.get('pipelines', [])
        if not pipelines:
            logger.warning("No pipelines found")
            return False

        for i, pipeline in enumerate(pipelines):
            # éªŒè¯pipelineçš„å¿…éœ€å­—æ®µï¼ˆåŸºäºæ–°çš„promptç»“æ„ï¼‰
            required_pipeline_keys = [
                'id', 'name', 'income_mechanism', 'parties_structure',
                'mvp', 'weak_link', 'revenue_trigger',
                'anti_bypass_strategies', 'risks_and_planB', 'first_step', 'labor_load_estimate'
            ]
            if not all(key in pipeline for key in required_pipeline_keys):
                logger.warning(
                    f"Pipeline {i} missing required keys. Has: {list(pipeline.keys())}, Required: {required_pipeline_keys}"
                )
                return False

            # éªŒè¯income_mechanismç»“æ„
            income_mechanism = pipeline.get('income_mechanism', {})
            if not all(key in income_mechanism
                       for key in ['type', 'trigger', 'settlement']):
                logger.warning(f"Pipeline {i} income_mechanism incomplete")
                return False

            # éªŒè¯parties_structureç»“æ„
            parties = pipeline.get('parties_structure', [])
            if not parties:
                logger.warning(f"Pipeline {i} has empty parties_structure")
                return False

            # éªŒè¯æ¯ä¸ªå‚ä¸æ–¹çš„ç»“æ„
            for j, party in enumerate(parties):
                required_party_keys = [
                    'party', 'role_type', 'resources', 'role_value',
                    'make_them_happy'
                ]
                if not all(key in party for key in required_party_keys):
                    logger.warning(
                        f"Pipeline {i} party {j} missing keys. Has: {list(party.keys())}, Required: {required_party_keys}"
                    )
                    return False

                # éªŒè¯role_typeå€¼
                valid_role_types = ['éœ€æ±‚æ–¹', 'äº¤ä»˜æ–¹', 'èµ„é‡‘æ–¹', 'ç»Ÿç­¹æ–¹']
                if party.get('role_type') not in valid_role_types:
                    logger.warning(
                        f"Pipeline {i} party {j} has invalid role_type: {party.get('role_type')}"
                    )
                    return False

            # framework_logic is no longer required - removed validation

            # éªŒè¯labor_load_estimateç»“æ„
            labor_load = pipeline.get('labor_load_estimate', {})
            if not all(key in labor_load
                       for key in ['hours_per_week', 'level', 'alternative']):
                logger.warning(f"Pipeline {i} labor_load_estimate incomplete")
                return False

        return True

    def _get_fallback_result(self, form_data: Dict[str,
                                                   Any]) -> Dict[str, Any]:
        """é™çº§è¿”å›ç»“æœï¼ˆå½“AIè°ƒç”¨å¤±è´¥æ—¶ï¼‰- åŸºäºæœ€æ–°promptè¦æ±‚çš„å®Œæ•´ç»“æ„"""
        project_name = form_data.get('projectName', 'é¡¹ç›®')
        project_description = form_data.get('projectDescription', '')
        key_persons = form_data.get('keyPersons', [])

        # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è¡¥å……è§’è‰²
        needs_additional_roles = len(key_persons) < 2  # ç®€å•è§„åˆ™ï¼šå°‘äº2ä¸ªäººç‰©æ—¶å»ºè®®è¡¥å……

        # åˆ†æç°æœ‰äººç‰©çš„è§’è‰²ç±»å‹åˆ†å¸ƒ
        existing_role_types = set()
        for person in key_persons:
            original_role = person.get('role', '')
            if original_role:
                role_type = self.get_role_type_by_identifier(original_role)
                existing_role_types.add(role_type)

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å…³é”®è§’è‰²ç±»å‹
        required_types = {'éœ€æ±‚æ–¹', 'äº¤ä»˜æ–¹'}
        missing_types = required_types - existing_role_types
        if missing_types:
            needs_additional_roles = True

        # æ„å»ºå‚ä¸æ–¹ç»“æ„ï¼ˆä¿ç•™æ‰€æœ‰ç”¨æˆ·è¾“å…¥çš„å…³é”®äººç‰©ï¼‰
        parties_structure = [{
            "party":
            "è®¾è®¡è€…ï¼ˆä½ ï¼‰",
            "role_type":
            "ç»Ÿç­¹æ–¹",
            "resources": ["ç»Ÿç­¹åè°ƒèƒ½åŠ›", "è§„åˆ™åˆ¶å®š", "åˆä½œä¼™ä¼´ç­›é€‰æ ‡å‡†", "ç»“ç®—ç®¡ç†"],
            "role_value":
            "ä½œä¸ºè¿æ¥å™¨å’Œè§„åˆ™åˆ¶å®šè€…ï¼Œç¡®ä¿å„æ–¹åˆä½œé¡ºç•…ï¼Œæ§åˆ¶æ ¸å¿ƒç¯èŠ‚",
            "make_them_happy":
            "é€šè¿‡æ’®åˆæœåŠ¡è·å¾—ç¨³å®šçš„éåŠ³åŠ¡æ”¶å…¥ï¼Œå»ºç«‹å¯æŒç»­çš„å•†ä¸šç®¡é“"
        }]

        # ä¸ºæ¯ä¸ªå…³é”®äººç‰©åˆ†é…åˆé€‚çš„role_type
        role_type_mapping = {
            0: "éœ€æ±‚æ–¹",  # ç¬¬ä¸€ä¸ªäººç‰©é»˜è®¤ä¸ºéœ€æ±‚æ–¹
            1: "äº¤ä»˜æ–¹",  # ç¬¬äºŒä¸ªäººç‰©é»˜è®¤ä¸ºäº¤ä»˜æ–¹
        }

        for i, person in enumerate(key_persons):
            name = person.get('name', f'å…³é”®äººç‰©{i+1}')
            resources = person.get('resources', ['ä¸“ä¸šæŠ€èƒ½', 'å®¢æˆ·åŸºç¡€'])
            make_happy = person.get('make_happy', ['è·å¾—æ”¶ç›Š', 'æ‰©å±•ä¸šåŠ¡'])

            # å¦‚æœæœ‰åŸå§‹roleä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨roleç±»å‹åˆ¤æ–­ï¼Œå¦åˆ™ä½¿ç”¨ç´¢å¼•æ˜ å°„
            original_role = person.get('role', '')
            if original_role:
                role_type = self.get_role_type_by_identifier(original_role)
            else:
                role_type = role_type_mapping.get(i, "äº¤ä»˜æ–¹")  # è¶…è¿‡2ä¸ªçš„é»˜è®¤ä¸ºäº¤ä»˜æ–¹

            parties_structure.append({
                "party":
                name,
                "role_type":
                role_type,
                "resources":
                resources if resources else ["ä¸“ä¸šèƒ½åŠ›", "å®¢æˆ·èµ„æº"],
                "role_value":
                f"åœ¨é—­ç¯ä¸­æä¾›{role_type}çš„æ ¸å¿ƒä»·å€¼ï¼Œç¡®ä¿æœåŠ¡è´¨é‡å’Œå®¢æˆ·æ»¡æ„åº¦",
                "make_them_happy":
                self.format_make_happy(make_happy)
            })

        # æ·»åŠ å¾…è¡¥é½è§’è‰²ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if needs_additional_roles and missing_types:
            for missing_type in missing_types:
                role_name_mapping = {
                    "éœ€æ±‚æ–¹": "æ¸ é“å®¢æˆ·æº",
                    "äº¤ä»˜æ–¹": "ä¸“ä¸šæœåŠ¡æ–¹"
                }
                role_name = role_name_mapping.get(missing_type, "åˆä½œä¼™ä¼´")

                parties_structure.append({
                    "party":
                    f"ã€å¾…è¡¥é½ã€‘{role_name}",
                    "role_type":
                    missing_type,
                    "resources": ["å¾…ç¡®å®šçš„å…³é”®èµ„æº", "å¾…åŒ¹é…çš„åˆä½œèƒ½åŠ›"],
                    "role_value":
                    f"è¡¥é½{missing_type}è§’è‰²ï¼Œå®Œå–„é—­ç¯ç»“æ„ï¼Œç¡®ä¿ç®¡é“å¯æŒç»­è¿è¡Œ",
                    "make_them_happy":
                    "é€šè¿‡äº’åˆ©å…±èµ¢çš„åˆä½œæ¨¡å¼ï¼Œå®ç°å„æ–¹ä»·å€¼æœ€å¤§åŒ–"
                })

        return {
            "overview": {
                "situation":
                f"åŸºäºã€æ„è¯†+èƒ½é‡+èƒ½åŠ›=ç»“æœã€‘å…¬å¼åˆ†æï¼š{project_name}å…·å¤‡åˆæ­¥èµ„æºåŸºç¡€ï¼Œè®¾è®¡è€…ä½œä¸ºç»Ÿç­¹æ–¹æ•´åˆç°æœ‰å…³é”®äººç‰©èµ„æºï¼Œæ„å»ºæ’®åˆå‹éåŠ³åŠ¡æ”¶å…¥ç®¡é“ã€‚æ„è¯†æ¥è‡ªè®¾è®¡è€…çš„è§„åˆ™è®¾è®¡ï¼Œèƒ½é‡æ¥è‡ªå…³é”®äººç‰©çš„ç§¯æå‚ä¸ï¼Œèƒ½åŠ›å€Ÿç”¨å„æ–¹ä¸“ä¸šèµ„æºã€‚",
                "core_insight":
                "åˆ©ç”¨ç°æœ‰å…³é”®äººç‰©çš„ä¸“ä¸šèƒ½åŠ›å’Œå®¢æˆ·åŸºç¡€ï¼Œè®¾è®¡è€…ä½œä¸ºç»Ÿç­¹æ–¹åˆ¶å®šåˆä½œè§„åˆ™å’Œè´¨é‡æ ‡å‡†ï¼Œé€šè¿‡æ’®åˆæœåŠ¡å»ºç«‹æŒç»­çš„éåŠ³åŠ¡æ”¶å…¥ç®¡é“ï¼Œå…³é”®åœ¨äºé˜²ç»•è¿‡æœºåˆ¶å’Œå…±ç®¡ç»“ç®—ã€‚",
                "gaps": ["æ˜ç¡®åˆä½œç»†åˆ™", "å»ºç«‹é˜²ç»•è¿‡æœºåˆ¶"]
                if not needs_additional_roles else ["è¡¥å……æ¸ é“èµ„æºæ–¹", "å»ºç«‹åˆä½œæ ‡å‡†"],
                "suggested_roles_to_hunt":
                [] if not needs_additional_roles else [{
                    "role":
                    "æ¸ é“èµ„æºæ–¹",
                    "role_type":
                    "éœ€æ±‚æ–¹",
                    "why":
                    "éœ€è¦æµé‡å…¥å£å’Œå®¢æˆ·è·å–æ¸ é“ï¼Œç¡®ä¿ä¸šåŠ¡å¯æŒç»­å‘å±•",
                    "where_to_find":
                    "è¡Œä¸šåä¼šã€å•†ä¼šã€åŒåŸä¼ä¸šå®¶ç¾¤ã€ç›¸å…³ä¸šåŠ¡çš„æœ‹å‹åœˆ",
                    "outreach_script":
                    "æˆ‘ä»¬æœ‰ä¼˜è´¨çš„æœåŠ¡å›¢é˜Ÿå’Œæˆç†Ÿçš„ç®¡ç†ç»éªŒï¼Œæ­£åœ¨å¯»æ±‚ä¼˜è´¨åˆä½œä¼™ä¼´æ‰©å¤§ä¸šåŠ¡è¦†ç›–ï¼ŒæœŸå¾…ä¸æ‚¨æ¢è®¨åŒèµ¢åˆä½œæœºä¼š"
                }]
            },
            "pipelines": [{
                "id":
                "pipeline_1",
                "name":
                f"{project_name}æ’®åˆæœåŠ¡ç®¡é“",
                "income_mechanism": {
                    "type": "å±…é—´ï¼ˆæ’®åˆè´¹ï¼‰",
                    "trigger": "æ¯æ¬¡æˆåŠŸåŒ¹é…å¹¶å®Œæˆäº¤æ˜“æ—¶",
                    "settlement": "æŒ‰äº¤æ˜“é‡‘é¢çš„ç™¾åˆ†æ¯”æ”¶å–æˆ–å›ºå®šæ’®åˆè´¹"
                },
                "parties_structure":
                parties_structure,
                "framework_logic": {
                    "resource_chain":
                    "é€šè¿‡æ•´åˆå„æ–¹èµ„æºå½¢æˆä¾›éœ€åŒ¹é…é—­ç¯ï¼šéœ€æ±‚æ–¹æä¾›å®¢æˆ·å’Œéœ€æ±‚ä¿¡æ¯ï¼Œäº¤ä»˜æ–¹æä¾›ä¸“ä¸šæœåŠ¡èƒ½åŠ›ï¼Œè®¾è®¡è€…åˆ¶å®šåŒ¹é…è§„åˆ™å’Œè´¨é‡æ ‡å‡†ï¼Œç¡®ä¿äº¤æ˜“é¡ºåˆ©å®Œæˆ",
                    "motivation_match":
                    "éœ€æ±‚æ–¹è·å¾—ä¼˜è´¨æœåŠ¡è§£å†³æ–¹æ¡ˆï¼Œäº¤ä»˜æ–¹è·å¾—ç¨³å®šå®¢æˆ·æ¥æºï¼Œè®¾è®¡è€…é€šè¿‡æ’®åˆè·å¾—æŒç»­æ”¶ç›Šï¼Œå½¢æˆä¸‰æ–¹å…±èµ¢æ ¼å±€",
                    "designer_position":
                    "æ§åˆ¶å®¢æˆ·ç­›é€‰æ ‡å‡†ã€æœåŠ¡æä¾›å•†è®¤è¯ä½“ç³»ã€äº¤æ˜“æµç¨‹è§„èŒƒå’Œç»“ç®—ç¯èŠ‚ï¼Œç¡®ä¿æ‰€æœ‰äº¤æ˜“å¿…é¡»é€šè¿‡ç»Ÿç­¹æ–¹å®Œæˆ",
                    "designer_income": "å±…é—´æ”¶ç›Š - é€šè¿‡åˆ¶å®šè§„åˆ™å’Œæ§åˆ¶å…³é”®ç¯èŠ‚è·å¾—æ¯ç¬”äº¤æ˜“çš„æ’®åˆè´¹ç”¨"
                },
                "mvp":
                "å»ºç«‹ç®€å•çš„ä¾›éœ€ä¿¡æ¯æ”¶é›†å’ŒåŒ¹é…æœºåˆ¶ï¼Œå…ˆä»ç°æœ‰äººè„‰å¼€å§‹å°è§„æ¨¡æ’®åˆï¼ŒéªŒè¯å•†ä¸šæ¨¡å¼å¯è¡Œæ€§åé€æ­¥æ‰©å¤§è§„æ¨¡ã€‚",
                "weak_link":
                "åˆæœŸå¯èƒ½é¢ä¸´ä¾›éœ€åŒæ–¹ä¿¡ä»»å»ºç«‹çš„æŒ‘æˆ˜ï¼Œéœ€è¦é€šè¿‡æˆåŠŸæ¡ˆä¾‹å’Œå£ç¢‘ç§¯ç´¯æ¥å¼ºåŒ–å¹³å°å¯ä¿¡åº¦ã€‚",
                "revenue_trigger":
                "å±…é—´æ”¶ç›Šï¼šæ¯æ¬¡æˆåŠŸæ’®åˆäº¤æ˜“æ—¶æŒ‰æ¯”ä¾‹æˆ–å›ºå®šè´¹ç”¨æ”¶å–æ’®åˆè´¹",
                "risks_and_planB": [{
                    "risk": "ä¾›éœ€åŒæ–¹ç»•è¿‡å¹³å°ç›´æ¥åˆä½œ",
                    "mitigation": "å»ºç«‹ç‹¬å®¶åˆä½œåè®®ï¼Œæ§åˆ¶å…³é”®å®¢æˆ·ä¿¡æ¯ï¼Œè®¾è®¡é˜¶æ¢¯å¼å¥–åŠ±æœºåˆ¶"
                }, {
                    "risk": "ç«äº‰å¯¹æ‰‹è¿›å…¥å¸‚åœº",
                    "mitigation": "å»ºç«‹å·®å¼‚åŒ–æœåŠ¡æ ‡å‡†ï¼Œæ·±è€•ç»†åˆ†é¢†åŸŸï¼Œæé«˜è½¬æ¢æˆæœ¬"
                }],
                "first_step":
                "ä»ç°æœ‰äººè„‰ä¸­è¯†åˆ«2-3ä¸ªæ½œåœ¨çš„éœ€æ±‚æ–¹å’Œäº¤ä»˜æ–¹ï¼Œè®¾è®¡åˆæ­¥çš„åˆä½œè§„åˆ™å’Œè´¹ç”¨æ ‡å‡†ï¼Œå®‰æ’è¯•ç‚¹æ’®åˆé¡¹ç›®éªŒè¯æ¨¡å¼",
                "labor_load_estimate": {
                    "hours_per_week": "5-8å°æ—¶",
                    "level": "ä¸­åº¦",
                    "alternative":
                    "å»ºç«‹æ ‡å‡†åŒ–çš„ç­›é€‰å’ŒåŒ¹é…æµç¨‹ï¼ŒåŸ¹è®­åŠ©æ‰‹å¤„ç†æ—¥å¸¸å¯¹æ¥å·¥ä½œï¼Œè®¾è®¡è‡ªåŠ¨åŒ–çš„ä¿¡æ¯æ”¶é›†å’Œåˆæ­¥ç­›é€‰ç³»ç»Ÿ"
                }
            }]
        }
